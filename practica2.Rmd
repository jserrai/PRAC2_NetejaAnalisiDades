---
title: "practica2"
author: "Paula Sobrevals, Jordi Serra"
date: "05/01/2021"
output: html_document
---

```{r setup, include=FALSE,message= FALSE, warning=FALSE} 
knitr::opts_chunk$set(echo = TRUE)
library(lubridate)
library(ggplot2)
library(patchwork)
library(dplyr)
library(scales)
library(Hmisc)
library(gridExtra)
library(ggpubr)
library(raster)
library(forecast)
library(psych)
library(plotly)
library(crosstalk)
library(car)
require(pls)
```

## 1. Integració i selecció de les dades d’interès a analitzar:

Em escollit el següent repositori per que conté diferents valors i tipologies, a l'hora que disposa de dos fitxers i ens permet crear un únic dataset a partir de fusionar els dos. Obtenim les dades del repositori: https://www.kaggle.com/lantanacamara/hong-kong-horse-racing
Aquest conté dades dels resultats de les 1561 curses de cavalls fetes a Hong Kong entre el 14 de Setembre del 2014 i el 16 de Juliol de 2017. 
Està organitzat amb dos fitxers: race-result-horse.csv i race-result-race.csv:

```{r message= FALSE, warning=FALSE}
horse.data <- read.csv("./race-result-horse.csv")
race.data <- read.csv("./race-result-race.csv")
```

Unifiquem els dos datasets en un a partir de la variable comú als dos fitxers. Aquesta fa referencia al identificador de la carrera: __race_id__ i mostrem la dimensió de les observacions i les variables.
```{r message= FALSE, warning=FALSE}
dataset <- merge(horse.data, race.data, by = "race_id")
dim(dataset)
```


## 2. Neteja de les dades:

Abans de netejar les dades, hem de mirar què hi tenim a cada columna. Per fer-ho utilizarem la funció summary() que ens permet visualitzar i fer-nos una idea general general el dataset: 

```{r message= FALSE, warning=FALSE}
#head(dataset,5)
str(dataset)
paste("Nombre de variables:" ,length(colnames(dataset)))
```

Com podem veure, tenim 30 variables amb 30189 observacions. Com que hi ha moltes variables que estan repetides o que no aporten una informació vàlida, n'eliminarem algunes:

1. __incident_report__: Són comentaris sobre la cursa, no utilitzarem aquesta variable per als nostres anàlisis, per tant els podem eliminar.
2. __running_position_X__: Entenem que són les posicions intermitjes de la carrera. No ens aporta informació sobre abans de la carrera, sinó durant aquesta.
3. __SRC__: Tampoc ens aporta res més que el nom dels fitxers de dades.
4. __horse_number__: Depèn de cada cursa i no identifica el cavall, per tant deixem només el __horse_name__.
5. __race_number__: També és reduntant amb les altres variables.
6. __race_date__: La data de la carrera és indiferent per l'anàlisi de les dades. 
7. __sectional_time__: Tindrem en compte només el temps total de la carrera, no de cada volta.
8. __horse_id__ : Ja tenim un identificador pel cavall, el nom, per tant aquest és redundant.
9. __length_behind_winner__ : És redundant, ja tenim la posició final de la cursa.

```{r message= FALSE, warning=FALSE}
eliminar <- c("running_position_1","running_position_2","running_position_3","running_position_4","running_position_5","running_position_6","incident_report","src","race_number","horse_number","horse_id","sectional_time","length_behind_winner")
dataset_clean <- dataset[ , !(names(dataset) %in% eliminar)]
dataset_clean[] <- lapply(dataset_clean, as.character)
attach(dataset_clean) # Per poder fer referencia directament a les variables
```


### 2.1. Les dades contenen zeros o elements buits? Com gestionaries aquests casos?

Fent una ullada al dataset, veiem que alguns valors _NA_ estan representats com a "---", "N", "SH" o "HD". Canviarem aquests valors a _NA_ per a poder treballar amb la mateixa notació. 
A més a més, a la columna de __length_behind_winner__ (la distància del cavall en qüestió en relació al primer), ens trobem valors representats com a "-". Aquests corresponen al guanyador de la cursa, no té distància sobre sí mateix, és a dir, no són valors buits sinó que representen distància 0. Modificarem la notació per "0".
A la variable __finishing_position__, tenim diversos valors no numèrics, aquests estan representats amb diferents lletres. Per a utilitzar la mateixa notació, canviarem la variable a numèrica i aquells valors no numèrics passaran a estar representats amb "NA".

```{r echo=TRUE, message=FALSE, warning=FALSE}
dataset_clean[dataset_clean == "-"] <- "0"
dataset_clean[dataset_clean == "---"] <- NA
dataset_clean[dataset_clean == "N"] <- NA
dataset_clean[dataset_clean == "SH"] <- NA
dataset_clean[dataset_clean == "HD"] <- NA
dataset_clean$finishing_position  <- lapply(dataset_clean$finishing_position, as.character)
dataset_clean$finishing_position <- unlist(lapply(dataset_clean$finishing_position, as.integer)) # tots aquells valors que no s'hagin pogut transformar són els no numèrics, i restaran com a "NA".
```

Un cop ja tenim tots els valors buits amb la mateixa identificació, podem mirar si tenim gaires elements buits, i en quines variables.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#paste("Nombre de valors nulls:", sum(is.na(race_id)))
colSums(is.na(dataset_clean))
```

Podem observar que tenim alguns valors buits al nostre dataset. Primer ens centrarem en la variable __finishing_position__. Determinem quin % de valors buits representa, per a poder decidir com actuem:

```{r message= FALSE, warning=FALSE}
paste("Proporció de valors nulls de la variable finishing_position:", format((sum(is.na(dataset_clean$finishing_position))/nrow(dataset_clean))*100, format = "f", digits = 3), "%")
```

Veiem que representa un valor molt baix de totes les nostres dades, així que aquest cas el podem gestionar eliminant les observacions nules. Si representés una proporció més gran de les nostres dades, al voltant de 15-20% hauriem d'imputar els missing values, utilitzant un anàlisi de regressió. 
Observem quans valors nuls tenim ara:

```{r message= FALSE, warning=FALSE}
dataset_clean <- dataset_clean[!(is.na(dataset_clean$finishing_position)),] # eliminem les files sense resultats.
colSums(is.na(dataset_clean))
```


Un cop netejada la variable, ja no tenim més valors buits en les altres columnes.
Tot i així, si mirem al dataset original, veiem que hi havia bastants valors buits. Aquests, estaven concentrats en les columnes que hem eliminat perque no ens aportaven informació útil.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#summary(dataset[,-30])
colSums(is.na(dataset[,eliminar]))
```

### 2.2. Identificació i tractament de valors extrems

Per a visualitzar els valors extrems, primer escollirem aquelles variables en les quals podem trobar-nos valors extrems.
De totes les variables del nostre dataset, només les variables continues poden tenir valors extrems, aquelles que categòriques o identificatives no en tindran ( __race_id__, __horse_name__, __jockey__, __trainer__, __draw__, __race_course__, __race_name__, __race_class__, __track__, __track_condition__, __finishing_position__, __length_behind_winner__, __race_distance__ ).
Primer transformem les variables continues a numèriques per poder trobar-ne els outliers.

```{r echo=TRUE, message=FALSE, warning=FALSE}
dataset_clean$actual_weight <- unlist(lapply(dataset_clean$actual_weight, as.numeric))
dataset_clean$declared_horse_weight <- unlist(lapply(dataset_clean$declared_horse_weight, as.numeric))
dataset_clean$finish_time <-  period_to_seconds(ms(dataset_clean$finish_time))
dataset_clean$win_odds <- unlist(lapply(dataset_clean$win_odds, as.numeric))
dataset_clean$race_distance <- as.factor(dataset_clean$race_distance)
```


> **Visualitzem els outliers:**

En el nostre dataset, hi tenim diverses curses de cavalls, aquestes tenen diferents distàncies de 1000m a 2400m. Segons amb quines variables hem de determinar els outliers tenint en compte la distància de la cursa, sinó aquest factor crearà un bias en els nostres resultats, si els tractem tots a la vegada quedarien amagats valors extrems dins de les longituds d'altres curses.


Utilitzem la representació gràfica (histograma i boxplot) per a visualitzar i detectar els outliers:

```{r echo=TRUE, message=FALSE, warning=FALSE, fig.width=10, fig.height=15}
hist_f <- ggplot(data = dataset_clean, aes(x=dataset_clean$finish_time)) + 
  facet_grid(rows = vars(dataset_clean$race_distance), scale = "free_y") +
  geom_histogram(binwidth=1, fill="#0c4c8a") +
  theme_minimal() +
  ggtitle("Histograma - Finnish time")
hist_aw <- ggplot(data = dataset_clean, aes(x=dataset_clean$actual_weight)) + 
  geom_histogram(binwidth=1, fill="#0c4c8a") +
  theme_minimal() +
  ggtitle("Histograma - Actual Weight")
hist_dw <- ggplot(data = dataset_clean, aes(x=dataset_clean$declared_horse_weight)) + 
  geom_histogram(binwidth=1, fill="#0c4c8a") +
  theme_minimal() +
  ggtitle("Histograma - Declared Weight")
hist_wo <- ggplot(data = dataset_clean, aes(x=dataset_clean$win_odds)) + 
  facet_grid(rows = vars(dataset_clean$race_distance), scale = "free_y") +
  geom_histogram(binwidth=1, fill="#0c4c8a") +
  theme_minimal() +
  ggtitle("Histograma - Win Odds")
box_f <- ggplot(dataset_clean) +
  aes(x = "", y = dataset_clean$finish_time) +
  facet_grid(cols = vars(dataset_clean$race_distance), scale = "free") +
  geom_boxplot(fill = "#0c4c8a", outlier.colour = "red") +
  ggtitle("Boxplot - Finnish time") +
  ylab("") + xlab("race distance") + 
  theme_minimal()
box_aw <- ggplot(dataset_clean) +
  aes(x = "", y = dataset_clean$actual_weight) +
  geom_boxplot(fill = "#0c4c8a",outlier.colour = "red") +
  ggtitle("Boxplot - Actual Weight") +
  ylab("") + xlab("race distance") +
  theme_minimal()
box_dw <- ggplot(dataset_clean) +
  aes(x = "", y = dataset_clean$declared_horse_weight) +
  geom_boxplot(fill = "#0c4c8a",outlier.colour = "red") +
  ggtitle("Boxplot - Declared weight") +
  ylab("") + xlab("race distance") +
  theme_minimal()
box_wo <- ggplot(dataset_clean) +
  aes(x = "", y = dataset_clean$win_odds) +
  facet_grid(cols = vars(dataset_clean$race_distance), scale = "free") +
  geom_boxplot(fill = "#0c4c8a",outlier.colour = "red") +
  ggtitle("Boxplot - Win Odds") +
  ylab("") + xlab("race distance") +
  theme_minimal()
hist_f + hist_aw + hist_dw + hist_wo + box_f + box_aw + box_dw + box_wo + plot_layout(nrow = 4, ncol = 2)
```


Per la variable del temps de finalització de cada carrera ( _Finish_time_ ), podem veure que hi ha cavalls que triguem especialment molt més que la resta en acabar la cursa. Podem veure també, com el pes del genet ( _Actual_weight_ ) està esbiaixat a l’alça, però tot i així hi ha alguns valors baixos, però no estan considerats outliers. El mateix passa amb el pes dels cavalls ( _Declared_weight_ ), que la majoria estan distribuïts centralment, però tot i això hi ha valors que queden marcats com a extrems. Podem veure que la variació de pes és molt petita i sembla que els cavalls més grans són els que fan curses més curtes, però no és significatiu. Pel que fa als _win_odds_, veiem que tot i la mitjana ser bastant baixa, tenim molts valors alts, els quals estan qualificats com a extrems.

> **Ara eliminem els outliers de cada una de les variables:**

Eliminarem tots aquells valors outliers. Tot i així, podem observar que a la variable _win_odds_, tots els outliers són els cavalls que tenen més probabilitats de guanyar. Com que el nostre estudi té a veure amb aquests, no eliminarem aquests outliers del nostre dataset i els tindrem en compte pels anàlisis posteriors.

```{r echo=TRUE, message=FALSE, warning=FALSE}
out_aw <- unlist(ggplot_build(box_aw)[["data"]][[1]][["outliers"]])
ind_aw <- which(dataset_clean$actual_weight %in% c(out_aw))
out_f <- unlist(ggplot_build(box_f)[["data"]][[1]][["outliers"]])
ind_f <- which(dataset_clean$finish_time %in% c(out_f))
out_dw <- unlist(ggplot_build(box_dw)[["data"]][[1]][["outliers"]])
ind_dw <- which(dataset_clean$declared_horse_weight %in% c(out_dw))
dataset_outliers <- dataset_clean[-c(ind_f,ind_dw,ind_aw),]
paste("Hem eliminat", (nrow(dataset_clean)-nrow(dataset_outliers)) , "outliers.")
paste("Ara el nostre dataset té", nrow(dataset_outliers), "observacions.")
dataset_clean <- dataset_outliers
dataset_clean <- dataset_clean[ , !(names(dataset_clean) %in% c("race_date"))]
```

## 3. Anàlisi de les dades.

Anem a fer ara l'anàlisi de les dades en profunditat.

### 3.1.  Selecció dels grups de dades que es volen analitzar/comparar (planificació dels anàlisis a aplicar).

Visualitzem el datset tal i com l'hem deixat després de la neteja:

```{r}
str(dataset_clean)
```

Tenim algunes variables numèriques contínues i d'altres categòriques. Treballarem amb totes les dades que tenim al _dataset_clean_, un cop hem eliminat els outliers i les variables repetides o que no eren útils. Separararem el dataset, i treballarem per separat amb les dades numèriques continues i les dades categòriques, ja que per a treballar-les molts cops calen diferents funcions. Finalment per a dur a terme els anàlisis, juntarem el dataset i trasformarem aquelles variables char en numèriques, així podrem analitzar-lo tot sencer.
A més a més, les nostres dades estan mesurades amb diferents llargades de curses, aquest fet, altera els valors d'algunes variables (per exemple, el temps d'una cursa de 1000m serà molt diferent al d'una cursa de 2400m) per tant, per a analitzar la forma de les dades caldrà separar-les per llargada. Es a dir, si l'analisi ho requereix, farem l'estudi per separat de cada tipus de cursa per poder diferenciar bé el comportament. Com veurem per exemple en la regresió.


### 3.2.  1. Comprovació de la normalitat i homogeneïtat de la variància.

Anem a veure la normalitat i homogeneitat de la variança.

Per a comporvar la normalitat i la homogeneitat, mirarem com estan distribuides les dades, per a comprovar si compleixen amb la hipotesi de la distribució normal de les dades, i si es comporten de manera homogenia. Ho farem de dues maneres: 

a) De manera visual: Amb un QQPlot, que ens permetrà veure si les dades s'ajusten a la normalitat, i amb un scatter plot que ens ajudarà a veure si es comporten de manera homogènia. 

b) Utiltzant tests específics: Per comporvar la normalitat usarem el Test de Shapiro–Wilk, el qual és considerat un dels test més potents per a contrastar la normalitat. Per comporvar la homogeneitat, usarem el Lavene Test i el Fligner-Killeen test segons si les nostres dades segueixen una distribució normal o no.


#### 1. Finish_time

```{r  message= FALSE, warning=FALSE} 
ggqqplot(data=dataset_clean, x="finish_time", color = "race_distance", ggtheme = theme_minimal(), conf.int = TRUE, size =0.1, title = "QQPlot - Finish Time")
SW <- list()
llargada = c(1000,1200,1400,1600,1800,2000,2200,2400)
i = 1
for (ll in llargada) {
  dades <- dataset_clean[dataset_clean$race_distance == ll,9]
  if (length(dades) < 5000) {
    SW[[i]] <- shapiro.test(dades)
    }
  else{
    SW[[i]] <- shapiro.test(dades[1:5000])
    }
  i = i+1
}
paste("La mitjana del valor W del Test de Shapiro–Wilk:" , mean(c(SW[[1]]$statistic[[1]],SW[[2]]$statistic[[1]],SW[[2]]$statistic[[1]],SW[[2]]$statistic[[1]],SW[[2]]$statistic[[1]],SW[[2]]$statistic[[1]],SW[[2]]$statistic[[1]],SW[[2]]$statistic[[1]])))
paste("El p-value mitjà del Test de Shapiro–Wilk:", mean(c(SW[[1]]$p.value[[1]],SW[[2]]$p.value[[1]],SW[[2]]$p.value[[1]],SW[[2]]$p.value[[1]],SW[[2]]$p.value[[1]],SW[[2]]$p.value[[1]],SW[[2]]$p.value[[1]],SW[[2]]$p.value[[1]])))

leveneTest(finish_time ~ as.factor(race_distance), data=dataset_clean)

```

Podem veure en el QQPlot que les dades de cada cursa s'ajusten molt bé a la normalitat.

A més el Test de Shapiro–Wilk també ens indica que les nostres dades són normalitzades, el _p-value_ és molt significant i el valor de Shapiro (W) és quasi 1. 
Segons el Test de Levene, veiem que tenim un _p-value_ inferior al nivell de significació (<0,05) per tant rebutjarem la hipòtesi nul·la d’homoscedasticitat i concluïm que la variable presenta variàncies estadísticament diferents per als diferents grups.

#### 2. Actual Weight

```{r  message= FALSE, warning=FALSE}
dades <- sample(seq(1,nrow(dataset_clean), by =1), 5000)
ggqqplot(data=dataset_clean, x="actual_weight", ggtheme = theme_minimal(), col = "#0c4c8a", conf.int = TRUE, size = 0.5, title = "QQPlot - Actual Weight")
shapiro.test(dataset_clean$actual_weight[dades])
leveneTest(actual_weight ~ as.factor(race_distance), data=dataset_clean)
```

En aquets cas, al _qqplot_ veiem que les dades segueixen la linia de la normalitat, tot i que cap al final s'estanquen al voltant de 132 jin (mesura de Xina ~= 65 kg).

Segons el Test de Shapiro–Wilk, veiem que les dades també estan normalitzades, el _p-value_ és molt significant i el valor de Shapiro (W) és quasi 1. 
Segons el Test de Levene, veiem que tenim un _p-value_ inferior al nivell de significació (<0,05) per tant rebutjarem la hipòtesi nul·la d’homoscedasticitat i concluïm que la variable presenta variàncies estadísticament diferents per als diferents grups.


#### 3. Declared Horse Weight

```{r message= FALSE, warning=FALSE}
dades <- sample(seq(1,nrow(dataset_clean), by =1), 5000)
ggqqplot(data=dataset_clean, x="declared_horse_weight", ggtheme = theme_minimal(), col = "#0c4c8a", conf.int = TRUE, size = 0.5, title = "QQPlot - Declared Horse Weight")
shapiro.test(dataset_clean$declared_horse_weight[dades])
leveneTest(declared_horse_weight ~ as.factor(race_distance), data=dataset_clean)
```

En aquets cas, al _qqplot_ veiem que les dades s'ajusten molt bé a la linia de la normalitat.

Segons el Test de Shapiro–Wilk, veiem que les dades també estan normalitzades, el _p-value_ és molt significant i el valor de Shapiro (W) és quasi 1. 
Segons el Test de Levene, veiem que tenim un _p-value_ inferior al nivell de significació (<0,05) per tant rebutjarem la hipòtesi nul·la d’homoscedasticitat i concluïm que la variable presenta variàncies estadísticament diferents per als diferents grups.


#### 4. Win Odds

```{r message= FALSE, warning=FALSE}
dades <- sample(seq(1,nrow(dataset_clean), by =1), 5000)
ggqqplot(data=dataset_clean, x="win_odds", ggtheme = theme_minimal(), col = "#0c4c8a", conf.int = TRUE, size = 0.5, title = "QQPlot - Win Odds")
shapiro.test(dataset_clean$win_odds[dades])
fligner.test(win_odds ~ as.factor(race_distance), data=dataset_clean)
```


En aquest cas, les dades sembla que no segueixen una forma normal. Al _QQPlot_, podem observar que les porbabilitats de guanyar estan repartides de manera "biestable", tant al 0% com al 100%, i molt poques entremig.

Pel que fa al Test de Shapiro–Wilk, el valor (W) és molt més baix que els anteriors (0.76), però el _p-value_ segueix sent significant.
En aquest cas, utilitzem el Test de Fligner-Killeen, ja que la nostra variable no segueix una distribució normal. Tot i així, veiem que altre cop tenim un _p-value_ inferior al nivell de significació (<0,05) per tant rebutjarem la hipòtesi nul·la d’homoscedasticitat i concluïm que la variable presenta variàncies estadísticament diferents per als diferents grups.


#### Homogeneitat:

Per a visualitzar la homogeneitat, separarem les dades segons la _race_distance_ i utilitzarem la _race_distance_ = 1200 com a mostra representativa, ja que és la més extensa (composta per ~9633 observacions). Veurem de manera senzilla que les variables numèriques, tal i com hem comprovat anteriorment amb els tests de Lavene i Fligner-Killeen, no són homogènies entre elles. 


```{r label="Homogeneitat"}
dataset_1200 <- dataset_clean[dataset_clean$race_distance == "1200",]

pp <- pairs.panels(dataset_1200[,c("finish_time","win_odds","actual_weight","declared_horse_weight")], method = "pearson", col = "#00AFBB",density = TRUE,  ellipses = TRUE,  show.points = TRUE, scale = TRUE, smoother = TRUE)
pp

```


### 3.3. Aplicació de proves estadístiques per comparar els grups de dades. En funció de les dades i de l’objectiu de l’estudi, aplicar proves de contrast d’hipòtesis, correlacions, regressions, etc. Aplicar almenys tres mètodes d’anàlisi diferents.


#### 1. Correlació:

Calcularem les correlacions de les variables, ja que aquestes ens poden ajudar a veure si alguna de les variables té més poder o està més relacionada amb qui guanyarà la cursa. Com que el nostre objectiu és acabar creant un model per a predir el resultat de la carrera, conèixer les correlacions ens pot ser molt útil per identificar aquelles variables que afecten més al resultat.


>Pearson

Per a veure les correlacions entre les variables numèriques utilitzarem la correlació de Pearson:

Mirem la correlación entre els valors que són _numerics_. Com ja hem comentat anteriorment, aquestes no es comporten igual i com podem veure hi ha una correlació directe entre el temps de la cursa i la distància. També sabem que el _finish_position_ és una representació del _finish_time_, sense estar correlacionada amb la distància.


```{r label="correlacio"}
paste("Correlació del finish time amb la race distance:" , cor(x=dataset_clean$finish_time, y=as.numeric(dataset_clean$race_distance)))
paste("Correlació del finish position amb la race distance:" ,cor(x=dataset_clean$finishing_position, y=as.numeric(dataset_clean$race_distance)))
```


Acabem de veure que el _finish_time_ depèn de la _race_distance_, sembla logic que el temps estigui relacionat amb la llargada de la cursa, per tant, per a fer les correlacions no usarem aquesta variable. En aquest cas, la variable _finish_position_ és una representació del _finish_time_, sense estar correlacionada amb el _race_distance_. Així doncs, usarem aquesta per a estudiar les correlacions entre la resta de variales:


```{r label="rcorr" }
eliminar <- c("race_distance", "finish_time")
dataset_numerical <- dataset_clean[ , !(names(dataset_clean) %in% eliminar)]
dataset_numerical <- select_if(dataset_numerical, is.numeric)

cor <- rcorr(as.matrix(dataset_numerical), type = "pearson")
cor
pairs.panels(dataset_numerical, 
             method = "pearson", # correlation method
             hist.col = "#00AFBB",
             density = TRUE,  # show density plots
             ellipses = TRUE, # show correlation ellipses
             cor = TRUE,
             show.points = FALSE
             )

```

Podem veure que no tenim correlacions entre les variables numèriques o són gairebé nules. A més a més, els _p-values_ tots són significants (<0.05). No tenir correlacions ens indica que les variables entre elles són independents. És a dir, que podem analitzar-les sense trobar-nos biaixos de collinearitat.
En el _pairplot_, veiem que quasi hi ha homogeneitat entre les variables, tot i així _win_odds_ presenta petites homogeneitats amb les variables: amb _finishing_position_  hi veiem una homogeneitat positiva i amb _actual_weight_ hi veiem una petita homogeneitat negativa.


>ANOVA

Ara ens centrarem amb les correlacions entre variables categòriques, per a fer-ho utilitzarem la funció __ANOVA__, per a comparar les mitjanes entre més de dos grups de dades

```{r}

dataset_categoric <- dataset_clean[ , !(names(dataset_clean) %in% c(names(dataset_numerical),"finish_time"))]
dataset_categoric[] <- lapply(dataset_categoric, as.factor)
dataset_categoric$finishing_position <- dataset_clean$finishing_position

res.aov <- aov(finishing_position ~ horse_name + jockey + trainer + draw + race_course + race_class + race_distance + track_condition + track, data = dataset_categoric) 
summary(res.aov)

```

El resultat de la ANOVA té un _p-value_ significant (<0.05) per totes les variables, excepte _track_condition_. És a dir, tal i com hem vist amb el pearson amb les variables numèriques, les categòriques també són independents. Pel que fa al _track_condition_, no hi ha una diferència significant sobre la variable _final_position_ en relació al _track_condition_ (Fvalue = 1.5).

#### 2. Regressió:

Anem a comprovar ara la relació de dependencia entre les variables independent i la dependent que podem tenir en el nostre cas. 

Aquí tenim com a variable depenent la posició final i la resta com a independent. Podem veure a la grafica següent que agafant una única variable no tenim una clara dependencia entre aquestes, però generant el model per cada un dels diferents tipus de cursa, tenint en compte la llargada d'aquesta, veiem com el valor de relació R-squared és molt alt, per sobre del 0.85, demostrant que hi ha una forta dependencia entre les variables i la posició final del cavall en cada una de les curses.

```{r message= FALSE, warning=FALSE}
dades <- dataset_clean[dataset_clean$race_distance =="1200", ]
plot(finishing_position~win_odds,data=dades)

m1 <- lm(finishing_position~actual_weight+declared_horse_weight+win_odds+trainer+jockey+horse_name+race_class+race_course+track_condition+race_name+race_id,data=dades)
summary(m1)
```

OPCIO 2: DE REGRESSIÓ:

Primer transformem els valors categòrics a numèrics per a poder fer el PCA:
```{r message= FALSE, warning=FALSE}
dataset_num <- dataset_clean
dataset_num[] <- lapply(dataset_num, as.factor)
dataset_num[] <- lapply(dataset_num, as.numeric)
dataset_num <- dataset_num[ , !(names(dataset_num) %in% c("finish_time"))]
```

Separem les dades entre train i test:

```{r message= FALSE, warning=FALSE}
set.seed(999)
smp_size <- floor(0.75 * nrow(dataset_num))

train_ind <- sample(seq_len(nrow(dataset_num)), size = smp_size)

train <- dataset_num[train_ind, ]
test <- dataset_num[-train_ind, ]
test_y <- test[ , (names(test) %in% c("finishing_position"))]
test <- test[ , !(names(test) %in% c("finishing_position"))]
```

i ara ja podem calcular la regresió i el model de predicció, per veure que tal es comporta.
Regresió:
```{r message= FALSE, warning=FALSE}
m1 <- lm(finishing_position~., data = train)
summary(m1)
m1_pred <- predict(m1, test, ncomp = 7)
accuracy(test_y, m1_pred)
```




#### 3. PCA + Regressió:

Aquesta prova la farem per a comparar-la amb la regressió estàndard. Volem veure si podem millorar el model creat anteriorment amb la regressió, utilitzan els principal components necessaris com a predictors per a ajustar el model de manera més precisa.

Primer transformem els valors categòrics a numèrics per a poder fer el PCA:

```{r message= FALSE, warning=FALSE}
dataset_num <- dataset_clean
dataset_num[] <- lapply(dataset_num, as.factor)
dataset_num[] <- lapply(dataset_num, as.numeric)
dataset_num <- dataset_num[ , !(names(dataset_num) %in% c("finish_time"))]
```

Ara creem el PCA i visualitzem el resultats:
```{r message= FALSE, warning=FALSE}
pca <- prcomp(dataset_num, scale = TRUE)
summary(pca)
plot(summary(pca)$importance[3,])
```

Separem les dades entre train i test com s'ha fet abans :
```{r message= FALSE, warning=FALSE}
set.seed(999)
smp_size <- floor(0.75 * nrow(dataset_num))

train_ind <- sample(seq_len(nrow(dataset_num)), size = smp_size)

train <- dataset_num[train_ind, ]
test <- dataset_num[-train_ind, ]
test_y <- test[ , (names(test) %in% c("finishing_position"))]
test <- test[ , !(names(test) %in% c("finishing_position"))]
```


Finalment fem el PCR (principal component regression) i calculem l'accuracy del model trobat:
```{r message= FALSE, warning=FALSE}
pcr_model <- pcr(finishing_position~., data = train,scale =TRUE, validation = "CV")
pcr_pred <- predict(pcr_model, test, ncomp = 7)
accuracy(test_y, pcr_pred)
```

### 4. Representació dels resultats a partir de taules i gràfiques.

anem a veure ara la reprentació dels resultats en taules i gràfics dels resultats obtinguts, ho podem fer mitjançant la següent gràfica dinàmica en la que es pot seleccionar cada un dels caballs o les curses en que estem fent l'estudi.

```{r message= FALSE, warning=FALSE}
library(crosstalk)

dataset_clean$finishing_position <-  unlist(lapply(dataset_clean$finishing_position, as.factor))
dataset_clean$race_date <- dataset_outliers$race_date
tx <- highlight_key(dataset_clean[1:5000,])
widgets <- bscols(
  widths = c(12,12,12),
  filter_select("horse_name", "Horse_name", tx, ~horse_name),
  filter_checkbox("race_distance", "race_distance", tx, ~race_distance, inline = TRUE)
)
bscols(
  widths = c(4,6), widgets, 
  plot_ly(tx, x = ~race_date, y = ~finish_time, showlegend = TRUE) %>% 
    add_lines(color = ~finishing_position)
)
```
